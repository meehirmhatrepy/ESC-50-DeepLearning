{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport pylab\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport librosa    \nimport glob\nimport tensorflow as tf\nfrom keras.applications import VGG19, ResNet152, VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nimport keras\nimport torchaudio\nfrom skimage.transform import resize\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:52:44.466141Z","iopub.execute_input":"2023-09-06T05:52:44.466606Z","iopub.status.idle":"2023-09-06T05:52:57.519674Z","shell.execute_reply.started":"2023-09-06T05:52:44.466525Z","shell.execute_reply":"2023-09-06T05:52:57.518689Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"### Define the path to  audio dataset\npath = \"/kaggle/input/environmental-sound-classification-50/audio/audio/44100/\"\n\n# Lists to store audio data and labels\naudio_data = []\nlabels = []\n\n# Iterate through audio files and extract features\nfor (root, dirs, files) in os.walk(path, topdown=True):\n    for file in files:\n        if file.endswith(\".wav\"):\n            src = os.path.join(root, file)\n            target = (file.split(\"-\")[-1])[:-4]  # Extract target label from path\n            audio, sr = librosa.load(src, sr=44100)\n            mel_feat = librosa.feature.melspectrogram(y=audio, sr=sr)\n            power = librosa.power_to_db(mel_feat)\n            power_resized = resize(power, (224, 224))  # Resize to a consistent shape\n            audio_data.append(np.stack([power_resized] * 3, axis=-1))  # Convert to 3 channels\n            labels.append(target)\n\n# Convert lists to numpy arrays\naudio_data_array = np.array(audio_data)\nlabels_array = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:52:57.521515Z","iopub.execute_input":"2023-09-06T05:52:57.522293Z","iopub.status.idle":"2023-09-06T05:54:48.801675Z","shell.execute_reply.started":"2023-09-06T05:52:57.522257Z","shell.execute_reply":"2023-09-06T05:54:48.800613Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Convert labels to categorical format\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels_array)\nnum_classes = len(label_encoder.classes_)\none_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(audio_data_array, one_hot_labels, test_size=0.3, random_state=42)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:54:48.814066Z","iopub.execute_input":"2023-09-06T05:54:48.814694Z","iopub.status.idle":"2023-09-06T05:54:49.285417Z","shell.execute_reply.started":"2023-09-06T05:54:48.814661Z","shell.execute_reply":"2023-09-06T05:54:49.283635Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nvgg19_model = Sequential()\nvgg19_model.add(vgg19)\nvgg19_model.add(layers.Dense(512, activation='relu'))\nvgg19_model.add(layers.Dropout(0.5))\nvgg19_model.add(layers.Dense(256, activation='relu'))\nvgg19_model.add(layers.Flatten())\nvgg19_model.add(layers.Dense(224, activation='relu'))\nvgg19_model.add(layers.Dropout(0.5))\nvgg19_model.add(layers.Dense(num_classes, activation='softmax'))\n\nfor layer in vgg19.layers:  \n    layer.trainable = False\n\nvgg19_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:54:49.287285Z","iopub.execute_input":"2023-09-06T05:54:49.287990Z","iopub.status.idle":"2023-09-06T05:54:59.387153Z","shell.execute_reply.started":"2023-09-06T05:54:49.287954Z","shell.execute_reply":"2023-09-06T05:54:59.385960Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg19_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = vgg19_model.evaluate(X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet152 = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nresnet152_model = Sequential()\nresnet152_model.add(resnet152)\nresnet152_model.add(layers.Dense(512, activation='relu'))\nresnet152_model.add(layers.Dropout(0.5))\nresnet152_model.add(layers.Dense(256, activation='relu'))\nresnet152_model.add(layers.Flatten())\nresnet152_model.add(layers.Dense(224, activation='relu'))\nresnet152_model.add(layers.Dropout(0.5))\nresnet152_model.add(layers.Dense(num_classes, activation='softmax'))\n\nfor layer in resnet152.layers:  \n    layer.trainable = False\n\nresnet152_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:54:59.389951Z","iopub.execute_input":"2023-09-06T05:54:59.390308Z","iopub.status.idle":"2023-09-06T05:55:07.258085Z","shell.execute_reply.started":"2023-09-06T05:54:59.390272Z","shell.execute_reply":"2023-09-06T05:55:07.256919Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n234698864/234698864 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet152_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val, y_val))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:52:41.745174Z","iopub.status.idle":"2023-09-06T05:52:41.745940Z","shell.execute_reply.started":"2023-09-06T05:52:41.745687Z","shell.execute_reply":"2023-09-06T05:52:41.745709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = resnet152_model.evaluate(X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nmodel_CNN = Sequential()\n\n# Layer 1: 2D convolutional layer\nmodel_CNN.add(Conv2D(24, kernel_size=(6, 6), strides=(1, 1), input_shape=(224, 224, 3)))\nmodel_CNN.add(Activation('relu'))\n\n# Layer 2: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\n# Layer 3: 2D convolutional layer with LeakyReLU\nmodel_CNN.add(Conv2D(24, kernel_size=(6, 6), strides=(1, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\n\n# Layer 4: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\n# Layer 5: 2D convolutional layer with LeakyReLU\nmodel_CNN.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2)))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\n\n# Layer 6: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\n# Layer 7: 2D convolutional layer with LeakyReLU\nmodel_CNN.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2)))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\n\n# Layer 8: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\n# Layer 9: 2D convolutional layer with LeakyReLU\nmodel_CNN.add(Conv2D(64, kernel_size=(4, 4), strides=(1, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\n\n# Layer 10: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\n# Layer 11: 2D convolutional layer with LeakyReLU\nmodel_CNN.add(Conv2D(64, kernel_size=(4, 4), strides=(1, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\n\n# Layer 12: Batch normalization layer\nmodel_CNN.add(BatchNormalization())\n\nmodel_CNN.add(Flatten())\nmodel_CNN.add(Dense(200))\nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Dense(50, activation='softmax'))\n\n# Compile the model\nmodel_CNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 150\n\ntrain_datagen = datagen.flow(X_train, y_train, batch_size=batch_size)\n\nhistory = model_CNN.fit(train_datagen, \n                        steps_per_epoch=len(X_train) // batch_size, \n                        epochs=epochs, \n                        validation_data=(X_val, y_val))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model_CNN.evaluate(X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\n\n# Load the EfficientNetB0 model with pre-trained weights\neffnet_b0 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\neffnet_b0_model = Sequential()\n\n# Add the EfficientNetB0 base model\neffnet_b0_model.add(effnet_b0)\n\n# Add custom fully connected layers\neffnet_b0_model.add(layers.Dense(512, activation='relu'))\neffnet_b0_model.add(layers.Dropout(0.5))\neffnet_b0_model.add(layers.Dense(256, activation='relu'))\neffnet_b0_model.add(layers.Flatten())\neffnet_b0_model.add(layers.Dense(224, activation='relu'))\neffnet_b0_model.add(layers.Dropout(0.5))\neffnet_b0_model.add(layers.Dense(num_classes, activation='softmax'))\n\nfor layer in effnet_b0.layers:\n    layer.trainable = False\n\neffnet_b0_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:55:07.259519Z","iopub.execute_input":"2023-09-06T05:55:07.259927Z","iopub.status.idle":"2023-09-06T05:55:10.817432Z","shell.execute_reply.started":"2023-09-06T05:55:07.259887Z","shell.execute_reply":"2023-09-06T05:55:10.816409Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n16705208/16705208 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"effnet_b0_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = effnet_b0_model.evaluate(X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nvgg16_model = Sequential()\nvgg16_model.add(vgg16)\nvgg16_model.add(layers.Dense(512, activation='relu'))\nvgg16_model.add(layers.Dropout(0.5))\nvgg16_model.add(layers.Dense(256, activation='relu'))\nvgg16_model.add(layers.Flatten())\nvgg16_model.add(layers.Dense(224, activation='relu'))\nvgg16_model.add(layers.Dropout(0.5))\nvgg16_model.add(layers.Dense(num_classes, activation='softmax'))\n\nfor layer in vgg16.layers:  \n    layer.trainable = False\n\nvgg16_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T05:55:10.818765Z","iopub.execute_input":"2023-09-06T05:55:10.820096Z","iopub.status.idle":"2023-09-06T05:55:11.629357Z","shell.execute_reply.started":"2023-09-06T05:55:10.820058Z","shell.execute_reply":"2023-09-06T05:55:11.628381Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg16_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = vgg16_model.evaluate(X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [model_CNN, vgg16_model, vgg19_model, resnet152_model, effnet_b0_model]\nmodel_names = [\"model_CNN\", \"vgg16_model\", \"vgg19_model\", \"resnet152_model\", \"effnet_b0_model\"]\n\ntest_data = [X_test, X_test, X_test, X_test, X_test]\n\nmodel_metrics = []\n\nfor i, model in enumerate(models):\n    print(f\"Metrics for {model_names[i]}:\")\n    metrics = evaluate_model_graphical(model, test_data[i], y_test)\n    model_metrics.append([model_names[i]] + list(metrics))\n\ncolumns = [\"model_name\", \"accuracy\", \"precision\", \"recall\", \"f1_score\", \"mean_squared_error\", \"specificity\", \"sensitivity\", \"prevalence\"]\ndf = pd.DataFrame(model_metrics, columns=columns)\n\nselected_columns = [\"model_name\", \"specificity\", \"sensitivity\", \"prevalence\"]\ndf_selected = df[selected_columns]\n\nplt.figure(figsize=(12, 6))\nsns.heatmap(df_selected.set_index(\"model_name\"), annot=True, cmap=\"YlGnBu\", fmt=\".4f\")\nplt.title(\"Model Comparison: Metrics\")\n\n# Save the table as a PNG image\nplt.savefig(\"model_metrics_table.png\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}