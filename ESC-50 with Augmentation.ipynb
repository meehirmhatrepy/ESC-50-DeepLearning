{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":142598,"sourceType":"datasetVersion","datasetId":3151},{"sourceId":7187237,"sourceType":"datasetVersion","datasetId":4155210},{"sourceId":7187446,"sourceType":"datasetVersion","datasetId":4155244},{"sourceId":7187629,"sourceType":"datasetVersion","datasetId":4155462},{"sourceId":7262278,"sourceType":"datasetVersion","datasetId":4208994},{"sourceId":7192991,"sourceType":"datasetVersion","datasetId":4159534}],"dockerImageVersionId":30616,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport pylab\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport librosa \nimport pandas as pd\nimport glob\nfrom keras.applications import VGG19, ResNet152\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Concatenate, LeakyReLU, Conv2D, MaxPooling2D,Input\nfrom keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom keras import optimizers\nimport keras\nimport torchaudio\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\nimport pickle\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n%matplotlib inline\nfrom skimage.transform import resize\nfrom random import sample\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T20:00:31.168055Z","iopub.execute_input":"2023-12-28T20:00:31.168894Z","iopub.status.idle":"2023-12-28T20:00:46.456236Z","shell.execute_reply.started":"2023-12-28T20:00:31.168864Z","shell.execute_reply":"2023-12-28T20:00:46.455402Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a function to extract features from audio\ndef extract_features(file_path):\n    audio, sr = librosa.load(file_path, sr=22050)  # Load audio\n    mel_feat = librosa.feature.melspectrogram(y=audio, sr=sr)\n    power = librosa.power_to_db(mel_feat)\n    power_resized = resize(power, (224, 224))\n    return power_resized","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:32.073377Z","iopub.execute_input":"2023-12-27T08:36:32.074180Z","iopub.status.idle":"2023-12-27T08:36:32.079776Z","shell.execute_reply.started":"2023-12-27T08:36:32.074149Z","shell.execute_reply":"2023-12-27T08:36:32.078664Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Path to your audio dataset\npath = \"/kaggle/input/environmental-sound-classification-50/audio/audio/44100\"\n\n# Lists to store extracted data and labels\nlabels = []\naudio_data = []\n# Iterate through audio files and extract features\nfor (root, dirs, files) in os.walk(path, topdown=True):\n    for file in files:\n        if file.endswith(\".wav\"):\n            src = os.path.join(root, file)\n            target = (file.split(\"-\")[-1])[:-4]\n            power_resized = extract_features(src)\n            audio_data.append(np.stack([power_resized]*3, axis=-1))  # Convert to 3 channels\n            labels.append(target)  # Extract label from file name","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:33.060251Z","iopub.execute_input":"2023-12-27T08:36:33.060642Z","iopub.status.idle":"2023-12-27T08:38:14.978130Z","shell.execute_reply.started":"2023-12-27T08:36:33.060613Z","shell.execute_reply":"2023-12-27T08:38:14.976458Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Convert lists to numpy arrays\naudio_data_array = np.array(audio_data)\nlabels_array = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:38:14.980871Z","iopub.execute_input":"2023-12-27T08:38:14.983152Z","iopub.status.idle":"2023-12-27T08:38:15.394263Z","shell.execute_reply.started":"2023-12-27T08:38:14.983081Z","shell.execute_reply":"2023-12-27T08:38:15.393293Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Convert labels to categorical format\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels_array)\nnum_classes = len(label_encoder.classes_)\none_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(audio_data_array, one_hot_labels, test_size=0.3, random_state=42)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:38:15.395484Z","iopub.execute_input":"2023-12-27T08:38:15.395742Z","iopub.status.idle":"2023-12-27T08:38:15.944982Z","shell.execute_reply.started":"2023-12-27T08:38:15.395719Z","shell.execute_reply":"2023-12-27T08:38:15.943828Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n# Define your augmentation parameters\ndatagen = ImageDataGenerator(\n    width_shift_range=0.2,          # Width shift by 20%\n    height_shift_range=0.2,         # Height shift by 20%\n    shear_range=0.2,                # Shear intensity\n    zoom_range=-0.2,                 # Zoom by 20%\n    horizontal_flip=True,           # Random horizontal flipping\n    vertical_flip=True,             # Random vertical flipping\n    brightness_range=[0.5, 1.5],    # Adjust brightness\n    channel_shift_range=100.0,      # Channel shifting (RGB)\n    fill_mode='nearest'             # Fill mode for new pixels\n)\n\n# Prepare an empty list to store generated images and labels\ngenerated_data = []\ngenerated_labels = []\n\n# Define the number of images to generate for each class\nimages_per_class = 50\n\n# Loop through each class\nfor label in range(y_train.shape[1]):  # Assuming y_train is one-hot encoded\n    label_indices = np.where(y_train[:, label] == 1)[0]\n    selected_indices = np.random.choice(label_indices, images_per_class, replace=False)\n    \n    # For each selected index, generate augmented images\n    for idx in selected_indices:\n        image = X_train[idx]  # Get the image for augmentation\n        image = image.reshape((1,) + image.shape)  # Reshape for flow method\n        \n        # Flow method generates batches of augmented images\n        augmented_images = datagen.flow(image, batch_size=1)\n        \n        # Iterate through the generated images\n        for batch in augmented_images:\n            generated_data.append(batch[0])  # Store augmented image\n            generated_labels.append(label)  # Store corresponding label\n            break  # Break the loop after one image to move to the next index\n\n# Convert the generated data into numpy arrays\ngenerated_data = np.array(generated_data)\ngenerated_labels = np.array(generated_labels)\n\nfrom tensorflow.keras.utils import to_categorical\n\n# Convert generated_labels to one-hot encoded format\ngenerated_labels_onehot = to_categorical(generated_labels, num_classes=num_classes)\n\n# Merge generated images and labels with X_train and y_train\nX_train_augmented = np.concatenate((X_train, generated_data), axis=0)\ny_train_augmented = np.concatenate((y_train, generated_labels_onehot), axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T15:41:02.885909Z","iopub.execute_input":"2023-12-24T15:41:02.886676Z","iopub.status.idle":"2023-12-24T15:41:05.367526Z","shell.execute_reply.started":"2023-12-24T15:41:02.886642Z","shell.execute_reply":"2023-12-24T15:41:05.366713Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"audio_data_array.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:39:42.791286Z","iopub.execute_input":"2023-12-27T08:39:42.791712Z","iopub.status.idle":"2023-12-27T08:39:42.798447Z","shell.execute_reply.started":"2023-12-27T08:39:42.791681Z","shell.execute_reply":"2023-12-27T08:39:42.797426Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(2000, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Load the data back\nwith open('/kaggle/input/dataesc/test_dataS_50.pkl', 'rb') as f:\n    X_test, y_test = pickle.load(f)\n\nwith open('/kaggle/input/dataesc/train_dataS_50.pkl', 'rb') as f:\n    X_train_augmented, y_train_augmented = pickle.load(f)\n\nwith open('/kaggle/input/dataesc/val_dataS_50.pkl', 'rb') as f:\n    X_val, y_val = pickle.load(f)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:01:43.699482Z","iopub.execute_input":"2023-12-28T20:01:43.701126Z","iopub.status.idle":"2023-12-28T20:02:24.243011Z","shell.execute_reply.started":"2023-12-28T20:01:43.701081Z","shell.execute_reply":"2023-12-28T20:02:24.242034Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n# Load the model\nresnet152_model = load_model('/kaggle/input/resnet152-final/resnet152_modelS (2).h5')\nvgg19_model = load_model('/kaggle/input/vgg19-and-effnet/vgg19_model_100SF.keras')\neffnet_b0_model = load_model('/kaggle/input/vgg19-and-effnet/effnet_b0_model.keras')\nensemble_model = load_model('/kaggle/input/history-and-ensemble/ensemble_model.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:08:00.114728Z","iopub.execute_input":"2023-12-28T20:08:00.115117Z","iopub.status.idle":"2023-12-28T20:14:09.741187Z","shell.execute_reply.started":"2023-12-28T20:08:00.115090Z","shell.execute_reply":"2023-12-28T20:14:09.740317Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_classes = 50\n\ninput_shape = (224, 224, 3)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:09.743509Z","iopub.execute_input":"2023-12-28T20:14:09.743889Z","iopub.status.idle":"2023-12-28T20:14:09.748539Z","shell.execute_reply.started":"2023-12-28T20:14:09.743862Z","shell.execute_reply":"2023-12-28T20:14:09.747407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load  VGG19 model \nvgg19 = VGG19(input_shape=input_shape, include_top=False, weights=None)\nvgg19.load_weights('/kaggle/input/model-weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nvgg19_model = Sequential(name='custom_vgg19')\n\n# Add VGG19 layers to the model\nvgg19_model.add(vgg19)\nvgg19_model.add(Dense(512, activation='relu', name='custom_dense_a'))\nvgg19_model.add(Dropout(0.5, name='custom_drop1'))\nvgg19_model.add(Dense(256, activation='relu', name='custom_dense_b'))\nvgg19_model.add(Flatten(name='custom_flat'))\nvgg19_model.add(Dense(224, activation='relu', name='custom_dense_c'))\nvgg19_model.add(Dropout(0.5, name='custom_drop2'))\nvgg19_model.add(Dense(num_classes, activation='softmax', name='custom_dense_d'))\n\n# Freezing VGG19 layers\nfor layer in vgg19_model.layers[0].layers:\n    layer.trainable = False\n\n# Compiling the model\nvgg19_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Summary of the model\nvgg19_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:02:13.129965Z","iopub.execute_input":"2023-12-25T15:02:13.130629Z","iopub.status.idle":"2023-12-25T15:02:19.892380Z","shell.execute_reply.started":"2023-12-25T15:02:13.130596Z","shell.execute_reply":"2023-12-25T15:02:19.891485Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"custom_vgg19\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n                                                                 \n custom_dense_a (Dense)      (None, 7, 7, 512)         262656    \n                                                                 \n custom_drop1 (Dropout)      (None, 7, 7, 512)         0         \n                                                                 \n custom_dense_b (Dense)      (None, 7, 7, 256)         131328    \n                                                                 \n custom_flat (Flatten)       (None, 12544)             0         \n                                                                 \n custom_dense_c (Dense)      (None, 224)               2810080   \n                                                                 \n custom_drop2 (Dropout)      (None, 224)               0         \n                                                                 \n custom_dense_d (Dense)      (None, 50)                11250     \n                                                                 \n=================================================================\nTotal params: 23239698 (88.65 MB)\nTrainable params: 3215314 (12.27 MB)\nNon-trainable params: 20024384 (76.39 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train your model using model.fit\nhistory_vgg19 = vgg19_model.fit(X_train_augmented, y_train_augmented, batch_size=64,epochs=100, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:02:40.163688Z","iopub.status.idle":"2023-12-28T20:02:40.164028Z","shell.execute_reply.started":"2023-12-28T20:02:40.163864Z","shell.execute_reply":"2023-12-28T20:02:40.163880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = vgg19_model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:09.749561Z","iopub.execute_input":"2023-12-28T20:14:09.749858Z","iopub.status.idle":"2023-12-28T20:14:21.116483Z","shell.execute_reply.started":"2023-12-28T20:14:09.749834Z","shell.execute_reply":"2023-12-28T20:14:21.115715Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 10s 97ms/step - loss: 1.0377 - accuracy: 0.9467\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = vgg19_model.evaluate(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:21.119010Z","iopub.execute_input":"2023-12-28T20:14:21.119317Z","iopub.status.idle":"2023-12-28T20:14:24.659239Z","shell.execute_reply.started":"2023-12-28T20:14:21.119290Z","shell.execute_reply":"2023-12-28T20:14:24.658452Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 2s 78ms/step - loss: 0.9798 - accuracy: 0.9556\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet152 = ResNet152(weights=None, include_top=False, input_shape=input_shape)\nresnet152.load_weights('/kaggle/input/model-weights/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5')\nresnet152_model = Sequential()\nresnet152_model.add(resnet152)\nresnet152_model.add(layers.Dense(512, activation='relu'))\nresnet152_model.add(layers.Dropout(0.5))\nresnet152_model.add(layers.Dense(256, activation='relu'))\nresnet152_model.add(layers.Flatten())\nresnet152_model.add(layers.Dense(224, activation='relu'))\nresnet152_model.add(layers.Dropout(0.5))\nresnet152_model.add(layers.Dense(50, activation='softmax'))\n\nfor layer in resnet152_model.layers[0].layers:  \n    layer.trainable = False\n\nresnet152_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nresnet152_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:02:42.470286Z","iopub.execute_input":"2023-12-25T15:02:42.470671Z","iopub.status.idle":"2023-12-25T15:02:51.735496Z","shell.execute_reply.started":"2023-12-25T15:02:42.470640Z","shell.execute_reply":"2023-12-25T15:02:51.734648Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n                                                                 \n dense (Dense)               (None, 7, 7, 512)         1049088   \n                                                                 \n dropout (Dropout)           (None, 7, 7, 512)         0         \n                                                                 \n dense_1 (Dense)             (None, 7, 7, 256)         131328    \n                                                                 \n flatten (Flatten)           (None, 12544)             0         \n                                                                 \n dense_2 (Dense)             (None, 224)               2810080   \n                                                                 \n dropout_1 (Dropout)         (None, 224)               0         \n                                                                 \n dense_3 (Dense)             (None, 50)                11250     \n                                                                 \n=================================================================\nTotal params: 62372690 (237.93 MB)\nTrainable params: 4001746 (15.27 MB)\nNon-trainable params: 58370944 (222.67 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history_resnet152 = resnet152_model.fit(X_train_augmented, y_train_augmented, batch_size=32,epochs=100, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = resnet152_model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:24.660740Z","iopub.execute_input":"2023-12-28T20:14:24.661571Z","iopub.status.idle":"2023-12-28T20:14:34.207455Z","shell.execute_reply.started":"2023-12-28T20:14:24.661534Z","shell.execute_reply":"2023-12-28T20:14:34.206720Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 8s 142ms/step - loss: 1.7329 - accuracy: 0.9600\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = resnet152_model.evaluate(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:34.208862Z","iopub.execute_input":"2023-12-28T20:14:34.209219Z","iopub.status.idle":"2023-12-28T20:14:39.202887Z","shell.execute_reply.started":"2023-12-28T20:14:34.209185Z","shell.execute_reply":"2023-12-28T20:14:39.201901Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 4s 129ms/step - loss: 1.3390 - accuracy: 0.9556\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_effnet_model(base_model):\n    model = Sequential(name='custom_effnetb0')\n    model.add(base_model)\n    \n    # Add custom layers on top of the base model\n    model.add(Dense(512, activation='relu', name='custom_eff_Denselayer1'))\n    model.add(Dropout(0.5, name='custom_eff_dropout1'))\n    model.add(Dense(256, activation='relu', name='custom_eff_Denselayer2'))\n    model.add(Flatten(name='custom_eff_flat'))\n    model.add(Dense(224, activation='relu', name='custom_eff_Denselayer3'))\n    model.add(Dropout(0.5, name='custom_eff_dropout2'))\n    model.add(Dense(50, activation='softmax', name='custom_eff_Dense4'))\n    \n    # Set the base layers to non-trainable\n    for layer in model.layers[0].layers:\n        layer.trainable = False\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr = 0.00001), metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:03:58.579817Z","iopub.execute_input":"2023-12-25T15:03:58.580829Z","iopub.status.idle":"2023-12-25T15:03:58.590427Z","shell.execute_reply.started":"2023-12-25T15:03:58.580779Z","shell.execute_reply":"2023-12-25T15:03:58.589202Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"effnet_b0 = EfficientNetB0(input_shape=input_shape, include_top=False, weights=None)\neffnet_b0.load_weights('/kaggle/input/model-weights/efficientnetb0_notop.h5') \n\nfor layer in effnet_b0.layers:\n    layer.trainable = False\n\n    \neffnet_b0_model = build_effnet_model(effnet_b0)\n\neffnet_b0_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:03:59.069317Z","iopub.execute_input":"2023-12-25T15:03:59.070254Z","iopub.status.idle":"2023-12-25T15:04:03.070631Z","shell.execute_reply.started":"2023-12-25T15:03:59.070212Z","shell.execute_reply":"2023-12-25T15:04:03.069729Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"custom_effnetb0\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetb0 (Functional  (None, 7, 7, 1280)        4049571   \n )                                                               \n                                                                 \n custom_eff_Denselayer1 (De  (None, 7, 7, 512)         655872    \n nse)                                                            \n                                                                 \n custom_eff_dropout1 (Dropo  (None, 7, 7, 512)         0         \n ut)                                                             \n                                                                 \n custom_eff_Denselayer2 (De  (None, 7, 7, 256)         131328    \n nse)                                                            \n                                                                 \n custom_eff_flat (Flatten)   (None, 12544)             0         \n                                                                 \n custom_eff_Denselayer3 (De  (None, 224)               2810080   \n nse)                                                            \n                                                                 \n custom_eff_dropout2 (Dropo  (None, 224)               0         \n ut)                                                             \n                                                                 \n custom_eff_Dense4 (Dense)   (None, 50)                11250     \n                                                                 \n=================================================================\nTotal params: 7658101 (29.21 MB)\nTrainable params: 3608530 (13.77 MB)\nNon-trainable params: 4049571 (15.45 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"effnet_history = effnet_b0_model.fit(X_train_augmented, y_train_augmented, batch_size=64,epochs=100, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = effnet_b0_model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:39.204259Z","iopub.execute_input":"2023-12-28T20:14:39.204564Z","iopub.status.idle":"2023-12-28T20:14:45.465922Z","shell.execute_reply.started":"2023-12-28T20:14:39.204538Z","shell.execute_reply":"2023-12-28T20:14:45.465130Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 5s 58ms/step - loss: 0.5496 - accuracy: 0.9567\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = effnet_b0_model.evaluate(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:45.467215Z","iopub.execute_input":"2023-12-28T20:14:45.467518Z","iopub.status.idle":"2023-12-28T20:14:48.020266Z","shell.execute_reply.started":"2023-12-28T20:14:45.467492Z","shell.execute_reply":"2023-12-28T20:14:48.019416Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 1s 45ms/step - loss: 0.4999 - accuracy: 0.9522\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout, Reshape, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n\n\n# Load ResNet152 without top layers\nresnet152 = ResNet152(weights=None, include_top=False, input_shape=(224, 224, 3))\nresnet152.load_weights('/kaggle/input/model-weights/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n# Freeze layers in ResNet152\nfor layer in resnet152.layers:\n    layer.trainable = False\n\neffnet_b0 = EfficientNetB0(input_shape=input_shape, include_top=False, weights=None)\neffnet_b0.load_weights('/kaggle/input/model-weights/efficientnetb0_notop.h5') \n\n# Freeze layers in EfficientNetB0\nfor layer in effnet_b0.layers:\n    layer.trainable = False\n\n# Input layer\ninput_layer = Input(shape=(224, 224, 3))\n\n# Pass input through ResNet152 and EfficientNetB0 layers\nx_resnet = resnet152(input_layer)\nx_resnet = GlobalAveragePooling2D()(x_resnet)\n\nx_effnet = effnet_b0(input_layer)\nx_effnet = GlobalAveragePooling2D()(x_effnet)\n# Concatenate ResNet152 and EfficientNetB0 outputs\nx = Concatenate()([x_resnet, x_effnet])\n\n    # Reshape to fit LSTM input requirements\nx = Reshape((1, x.shape[1]))(x)\n\n    # LSTM layer\nx = LSTM(512)(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(224, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\n\n    # Define the final model\nensemble_model = Model(inputs=input_layer, outputs=output)\n\nensemble_model.compile(optimizer=Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nensemble_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:04:42.528211Z","iopub.execute_input":"2023-12-25T15:04:42.529121Z","iopub.status.idle":"2023-12-25T15:04:54.699671Z","shell.execute_reply.started":"2023-12-25T15:04:42.529086Z","shell.execute_reply":"2023-12-25T15:04:54.698762Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_6 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n                                                                                                  \n resnet152 (Functional)      (None, 7, 7, 2048)           5837094   ['input_6[0][0]']             \n                                                          4                                       \n                                                                                                  \n efficientnetb0 (Functional  (None, 7, 7, 1280)           4049571   ['input_6[0][0]']             \n )                                                                                                \n                                                                                                  \n global_average_pooling2d (  (None, 2048)                 0         ['resnet152[0][0]']           \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n global_average_pooling2d_1  (None, 1280)                 0         ['efficientnetb0[0][0]']      \n  (GlobalAveragePooling2D)                                                                        \n                                                                                                  \n concatenate (Concatenate)   (None, 3328)                 0         ['global_average_pooling2d[0][\n                                                                    0]',                          \n                                                                     'global_average_pooling2d_1[0\n                                                                    ][0]']                        \n                                                                                                  \n reshape (Reshape)           (None, 1, 3328)              0         ['concatenate[0][0]']         \n                                                                                                  \n lstm (LSTM)                 (None, 512)                  7866368   ['reshape[0][0]']             \n                                                                                                  \n dropout_2 (Dropout)         (None, 512)                  0         ['lstm[0][0]']                \n                                                                                                  \n dense_4 (Dense)             (None, 256)                  131328    ['dropout_2[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)         (None, 256)                  0         ['dense_4[0][0]']             \n                                                                                                  \n dense_5 (Dense)             (None, 224)                  57568     ['dropout_3[0][0]']           \n                                                                                                  \n dense_6 (Dense)             (None, 10)                   2250      ['dense_5[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 70478029 (268.85 MB)\nTrainable params: 8057514 (30.74 MB)\nNon-trainable params: 62420515 (238.12 MB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the ensemble model \nensemble_history = ensemble_model.fit(X_train_augmented, y_train_augmented, epochs=100, batch_size=64, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T19:55:49.168243Z","iopub.execute_input":"2023-12-28T19:55:49.168536Z","iopub.status.idle":"2023-12-28T19:55:49.173104Z","shell.execute_reply.started":"2023-12-28T19:55:49.168510Z","shell.execute_reply":"2023-12-28T19:55:49.172244Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = ensemble_model.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:14:48.021560Z","iopub.execute_input":"2023-12-28T20:14:48.021862Z","iopub.status.idle":"2023-12-28T20:15:02.420464Z","shell.execute_reply.started":"2023-12-28T20:14:48.021836Z","shell.execute_reply":"2023-12-28T20:15:02.419484Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 13s 167ms/step - loss: 0.2069 - accuracy: 0.9678\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = ensemble_model.evaluate(X_val,y_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:02.423355Z","iopub.execute_input":"2023-12-28T20:15:02.423679Z","iopub.status.idle":"2023-12-28T20:15:08.522345Z","shell.execute_reply.started":"2023-12-28T20:15:02.423652Z","shell.execute_reply":"2023-12-28T20:15:08.521424Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 5s 167ms/step - loss: 0.1438 - accuracy: 0.9733\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Accuracies on full original data are as below:**","metadata":{}},{"cell_type":"code","source":" loss, accuracy = vgg19_model.evaluate(audio_data_array, one_hot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:08.570337Z","iopub.status.idle":"2023-12-28T20:15:08.570853Z","shell.execute_reply.started":"2023-12-28T20:15:08.570574Z","shell.execute_reply":"2023-12-28T20:15:08.570597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" loss, accuracy = resnet152_model.evaluate(audio_data_array, one_hot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:08.567815Z","iopub.status.idle":"2023-12-28T20:15:08.568276Z","shell.execute_reply.started":"2023-12-28T20:15:08.568040Z","shell.execute_reply":"2023-12-28T20:15:08.568063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" loss, accuracy = effnet_b0_model.evaluate(audio_data_array, one_hot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:08.571985Z","iopub.status.idle":"2023-12-28T20:15:08.572429Z","shell.execute_reply.started":"2023-12-28T20:15:08.572195Z","shell.execute_reply":"2023-12-28T20:15:08.572217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" loss, accuracy = ensemble_model.evaluate(audio_data_array, one_hot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:18.485430Z","iopub.execute_input":"2023-12-28T20:15:18.486170Z","iopub.status.idle":"2023-12-28T20:15:18.490084Z","shell.execute_reply.started":"2023-12-28T20:15:18.486141Z","shell.execute_reply":"2023-12-28T20:15:18.489119Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n# Convert y_test to categorical labels if needed\ny_test_categorical = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n\n# Calculate predictions for each model\nresnet152_preds = resnet152_model.predict(X_test)\nvgg19_preds = vgg19_model.predict(X_test)\neffnet_preds = effnet_b0_model.predict(X_test)\nensemble_preds = ensemble_model.predict(X_test)\n\n# Calculate predictions for each model\n# Ensure predictions are in the same format as categorical labels\nresnet152_preds_categorical = np.argmax(resnet152_preds, axis=1)\nvgg19_preds_categorical = np.argmax(vgg19_preds, axis=1)\neffnet_preds_categorical = np.argmax(effnet_preds, axis=1)\nensemble_preds_categorical = np.argmax(ensemble_preds, axis=1)\n\n# Accuracy for each model\nresnet152_accuracy = accuracy_score(y_test_categorical, resnet152_preds_categorical)\nvgg19_accuracy = accuracy_score(y_test_categorical, vgg19_preds_categorical)\neffnet_accuracy = accuracy_score(y_test_categorical, effnet_preds_categorical)\nensemble_accuracy = accuracy_score(y_test_categorical, ensemble_preds_categorical)\n\n# Precision, Recall, F1-score for each model\nresnet152_precision = precision_score(y_test_categorical, resnet152_preds_categorical, average='weighted')\nvgg19_precision = precision_score(y_test_categorical, vgg19_preds_categorical, average='weighted')\neffnet_precision = precision_score(y_test_categorical, effnet_preds_categorical, average='weighted')\nensemble_precision = precision_score(y_test_categorical, ensemble_preds_categorical, average='weighted')\n\n\nresnet152_recall = recall_score(y_test_categorical, resnet152_preds_categorical, average='weighted')\nvgg19_recall = recall_score(y_test_categorical, vgg19_preds_categorical, average='weighted')\neffnet_recall = recall_score(y_test_categorical, effnet_preds_categorical, average='weighted')\nensemble_recall = recall_score(y_test_categorical, ensemble_preds_categorical, average='weighted')\n\nresnet152_f1 = f1_score(y_test_categorical, resnet152_preds_categorical, average='weighted')\nvgg19_f1 = f1_score(y_test_categorical, vgg19_preds_categorical, average='weighted')\neffnet_f1 = f1_score(y_test_categorical, effnet_preds_categorical, average='weighted')\nensemble_f1 = f1_score(y_test_categorical, ensemble_preds_categorical, average='weighted')\n\n# Displaying the evaluation metrics\nfinal_metrics = {\n    'Model': ['ResNet152', 'VGG19', 'EfficientNet', 'Ensemble'],\n    'Accuracy': [resnet152_accuracy, vgg19_accuracy, effnet_accuracy, ensemble_accuracy],\n    'Precision': [resnet152_precision, vgg19_precision, effnet_precision, ensemble_precision],\n    'Recall': [resnet152_recall, vgg19_recall, effnet_recall, ensemble_recall],\n    'F1-Score': [resnet152_f1, vgg19_f1, effnet_f1, ensemble_f1]\n}\n\nfinal_metrics_df = pd.DataFrame(final_metrics)\nprint(final_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T20:15:46.729765Z","iopub.execute_input":"2023-12-28T20:15:46.730130Z","iopub.status.idle":"2023-12-28T20:16:14.097861Z","shell.execute_reply.started":"2023-12-28T20:15:46.730103Z","shell.execute_reply":"2023-12-28T20:16:14.096890Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 7s 127ms/step\n29/29 [==============================] - 2s 77ms/step\n29/29 [==============================] - 3s 44ms/step\n29/29 [==============================] - 10s 160ms/step\n          Model  Accuracy  Precision    Recall  F1-Score\n0     ResNet152  0.960000   0.965741  0.960000  0.960393\n1         VGG19  0.946667   0.950992  0.946667  0.946990\n2  EfficientNet  0.956667   0.960175  0.956667  0.956704\n3      Ensemble  0.967778   0.970980  0.967778  0.967572\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
